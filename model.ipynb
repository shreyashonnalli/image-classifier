{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2D is spatial convolution over images\n",
    "# MaxPooling2D is a max pooling operation for 2D spatial data\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "# sequential is good for when we have a single dataset and looking for single output\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.experimental.numpy.random.seed(seed)\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = 'tonsildb/'\n",
    "dataset = []\n",
    "label = []\n",
    "\n",
    "no_pha_images = os.listdir(image_directory+'no_pharyngitis')\n",
    "for i, image_name in enumerate(no_pha_images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    image = cv2.imread(image_directory + 'no_pharyngitis/' + image_name)\n",
    "    image = Image.fromarray(image, 'RGB')\n",
    "    image = image.resize((256, 256))\n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    dataset.append(image)\n",
    "    label.append(0)\n",
    "\n",
    "\n",
    "pha_images = os.listdir(image_directory + 'pharyngitis/')\n",
    "for i, image_name in enumerate(pha_images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    image = cv2.imread(image_directory + 'pharyngitis/' + image_name)\n",
    "    image = Image.fromarray(image, 'RGB')\n",
    "    image = image.resize((256, 256))\n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    dataset.append(image)\n",
    "    label.append(1)\n",
    "    \n",
    "images_np = dataset\n",
    "labels_np = label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness(img, low, high):\n",
    "    value = random.uniform(low, high)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hsv = np.array(hsv, dtype = np.float64)\n",
    "    hsv[:,:,1] = hsv[:,:,1]*value\n",
    "    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
    "    hsv[:,:,2] = hsv[:,:,2]*value \n",
    "    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
    "    hsv = np.array(hsv, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    return img\n",
    "\n",
    "def channel_shift(img, value):\n",
    "    value = int(random.uniform(-value, value))\n",
    "    img = img + value\n",
    "    img[:,:,:][img[:,:,:]>255]  = 255\n",
    "    img[:,:,:][img[:,:,:]<0]  = 0\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def horizontal_flip(img):    \n",
    "    return cv2.flip(img, 1)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness_and_flip(image_np):\n",
    "    image_np = horizontal_flip(image_np)\n",
    "    image_np = brightness(image_np, 0.7, 1.2)\n",
    "    return image_np\n",
    "\n",
    "\n",
    "for i in range(len(images_np)):\n",
    "    to_append = horizontal_flip(images_np[i])\n",
    "    images_np.append(to_append)\n",
    "    labels_np.append(labels_np[i])\n",
    "    to_append = brightness(images_np[i], 0.7, 1.2)\n",
    "    images_np.append(to_append)\n",
    "    labels_np.append(labels_np[i])\n",
    "    to_append = brightness_and_flip(images_np[i])\n",
    "    images_np.append(to_append)\n",
    "    labels_np.append(labels_np[i])\n",
    "    \n",
    "print(len(images_np))\n",
    "print(len(labels_np))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image(image_np):\n",
    "    plt.imshow(image_np/255.0)\n",
    "    plt.show()\n",
    "\n",
    "def print_image_grayscale(image_np, gray = False):\n",
    "    if gray == True:\n",
    "        plt.imshow(image_np/255.0, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(image_np)\n",
    "    plt.show()\n",
    "\n",
    "def combine_mask_with_image(mask, image_np):\n",
    "    image_np = cv2.bitwise_and(image_np, image_np, mask = mask)\n",
    "    return image_np\n",
    "\n",
    "\n",
    "def apply_threshold_rgb(images_np, lower = np.array([0,0,0]), upper = np.array([255,255,255])):\n",
    "    binary_np = cv2.inRange(images_np, lower, upper)\n",
    "    return binary_np\n",
    "\n",
    "\n",
    "def apply_threshold_grayscale(grayscale_np, lower=0, upper=255):\n",
    "    binary_np = cv2.inRange(grayscale_np, lower, upper)\n",
    "    return binary_np\n",
    "\n",
    "def convert_to_grayscale(images_np):\n",
    "    #gray_np = np.dot(images_np[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "    gray_np = cv2.cvtColor(images_np, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_np\n",
    "\n",
    "def convert_rgb_to_ycbcr(image_np):\n",
    "    image_np = image_np.astype(np.uint8)\n",
    "    ycbcr_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2YCrCb)\n",
    "    return ycbcr_image\n",
    "\n",
    "def resize_image(image_np, new_size):\n",
    "    resize_image = cv2.resize(image_np, new_size)\n",
    "    return resize_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection and smoothing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_blur(images_np):\n",
    "    # second argument is kernel size. Larger the kernel size means wider distribution of weights\n",
    "    # third argument is sigma - larger the sigma the more spread out the blur effect. Pixels far away have greater influence on final output\n",
    "    # A larger kernel size can help to smooth out larger features in the image, while a larger sigma value can help to remove finer details and noise\n",
    "    blurred_image_np = cv2.GaussianBlur(images_np, (7, 7), 15)\n",
    "    return blurred_image_np\n",
    "\n",
    "def calculate_gradient_mag_using_canny(grayscale_np, lower_thresh = 0, upper_thresh = 0):\n",
    "    #second argument - grad mag threshold. Any edge with grad mag lower than this is discarded as weak edges\n",
    "    #third argument - grad mag threshold but any edge with grad mag higher considered as strong edges\n",
    "    grayscale_np = grayscale_np.astype(np.uint8)\n",
    "    edges_np = cv2.Canny(grayscale_np,lower_thresh, upper_thresh)\n",
    "    return edges_np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision modelling and detecting shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_circles_from_edges(edges, min_radius = 0, max_radius = 100):\n",
    "    #first argument is the binary image of edges\n",
    "    #Second argument is variation of hough transform -\n",
    "    #variants include cv2.HOUGH_STANDARD, cv2.HOUGH_PROBABALISTIC, cv2.HOUGH_GRADIENT\n",
    "    #third argument is resolution of accumulator array - represents ratio between image resolution and resolution of accumulator array - determines granularity of search - smaller leads to more finer search\n",
    "    #fourth argument is the minimum distance between centers of detected circles\n",
    "    #param1 is the higher threshold for the canny edge detector\n",
    "    #fourth argument is Min and max radius of circles found\n",
    "    circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1,20, param1=50, param2= 30, minRadius=min_radius, maxRadius=max_radius)\n",
    "    \n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        distances = np.sqrt((circles[:, 0] - edges.shape[1]/2)**2 + (circles[:, 1] - edges.shape[0]/2)**2)\n",
    "        sorted_circles = circles[np.argsort(distances)]\n",
    "        sorted_circles = np.expand_dims(sorted_circles, axis=0)\n",
    "        return sorted_circles\n",
    "    \n",
    "    return circles\n",
    "\n",
    "def create_square_mask(circle, image_np):\n",
    "    print(circle)\n",
    "    x, y = circle[:2]\n",
    "    size = circle[2]\n",
    "    mask = np.zeros(image_np.shape[:2], dtype=np.uint8)\n",
    "    mask[y-size:y+size, x-size:x+size] = 1\n",
    "    return mask\n",
    "\n",
    "def crop_image(image_np, circle):\n",
    "    square_size = circle[2] * 2\n",
    "    x_start = circle[0]-circle[2]\n",
    "    y_start = circle[1] - circle[2]\n",
    "    cropped = image_np[y_start: y_start+square_size, x_start:x_start+square_size]\n",
    "    return cropped\n",
    "\n",
    "def draw_circle_on_image(image_np, circle):\n",
    "    image_np = cv2.circle(image_np, (circle[0],circle[1]),circle[2],(0,255,0),2)\n",
    "    print_image(image_np)\n",
    "    return image_np\n",
    "\n",
    "def create_and_apply_circle_mask(image_np, circles):\n",
    "    if circles is not None:\n",
    "        circle = circles[0][0]\n",
    "        mask = np.zeros(image_np.shape[:2], dtype=np.uint8)\n",
    "        cv2.circle(mask, (circle[0], circle[1]), circle[2], (255, 255, 255), -1)\n",
    "        circle_result = cv2.bitwise_and(image_np, image_np, mask=mask)\n",
    "        #print_image(circle_result)\n",
    "        result = crop_image(circle_result, circle)\n",
    "    else:\n",
    "        result = np.zeros_like(image_np)\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images_np)):\n",
    "    \n",
    "    blurred_np= apply_gaussian_blur(images_np[i])\n",
    "    gray_np = convert_to_grayscale(blurred_np)\n",
    "    grad_mag_np = calculate_gradient_mag_using_canny(gray_np, 0, 5)\n",
    "    circles = get_circles_from_edges(grad_mag_np, 70, 100)\n",
    "    cropped_image_np = create_and_apply_circle_mask(images_np[i],circles)\n",
    "    images_np[i] = resize_image(cropped_image_np, (256,256))\n",
    "    \n",
    "    #print_image(images_np[i])\n",
    "    images_np[i] = images_np[i].astype('float32')/255.0\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(images_np)):\n",
    "#    images_np[i] = images_np[i]/255.0\n",
    "\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_indices, test_indices = next(stratified_split.split(images_np, labels_np))\n",
    "\n",
    "x_train = [images_np[i] for i in train_indices]\n",
    "y_train = [labels_np[i] for i in train_indices]\n",
    "x_test_list = [images_np[i] for i in test_indices]\n",
    "y_test = [labels_np[i] for i in test_indices]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test_list)\n",
    "y_train = np.array(y_train).reshape(-1,1)\n",
    "y_test = np.array(y_test).reshape(-1,1)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "for i in x_test_list:\n",
    "    #print_image(i)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = ResNet50(include_top=False, weights='imagenet',\n",
    "                 input_shape=(256, 256, 3), classes=2, pooling='avg')\n",
    "resnet_model = Sequential()\n",
    "resnet_model.add(model)\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(1, activation='sigmoid'))\n",
    "resnet_model.compile('adam', loss=tf.losses.BinaryCrossentropy(),\n",
    "                     metrics=['accuracy'])\n",
    "resnet_model.summary()\n",
    "'''\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model = Sequential()\n",
    "# Conv2D(No. of filters, dimensions of filter, activation function, expected image size(only first time))\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu',\n",
    "          padding=\"same\", input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1\n",
    ")\n",
    "'''\n",
    "hist = model.fit(x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    validation_split = 0.2,\n",
    "    verbose=1,\n",
    "    callbacks = [callback]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph for error and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='green', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='black', label='val_accuracy')\n",
    "fig.suptitle('accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('loss')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.abspath(os.path.join(\n",
    "    'models', 'tonsil_detector.h5'))\n",
    "model = tf.keras.models.load_model(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_vis = np.expand_dims(x_test[0], axis=0)\n",
    "print(img_to_vis.shape)\n",
    "\n",
    "conv_layer_index = [0,2,4,7,9]\n",
    "outputs = [model.layers[i].output for i in conv_layer_index]\n",
    "feature_model = Model(inputs=model.inputs, outputs=outputs)\n",
    "\n",
    "feature_output = feature_model.predict(img_to_vis)\n",
    "\n",
    "columns = 8\n",
    "rows = 4\n",
    "for ftr in feature_output:\n",
    "    #pos = 1\n",
    "    fig=plt.figure(figsize=(8,4))\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig =plt.subplot(rows, columns, i)\n",
    "        fig.set_xticks([])  #Turn off axis\n",
    "        fig.set_yticks([])\n",
    "        plt.imshow(ftr[0, :, :, i-1], cmap='gray')\n",
    "        #pos += 1\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(x_test)\n",
    "y_preds = np.round(y_preds)\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Get misclassified indices\n",
    "misclassified_idx = np.where(y_preds != y_test)[0]\n",
    "misclassified_idx = misclassified_idx.tolist()\n",
    "for i in misclassified_idx:\n",
    "    print_image(x_test_list[i]*255.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models', 'tonsil_detector.h5'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building feature extractor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Sequential()\n",
    "feature_extractor.add(Conv2D(32, (3, 3), 1, activation='relu',\n",
    "          padding=\"same\", input_shape=(256, 256, 3)))\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "feature_extractor.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Conv2D(32, (3, 3), 1, activation='relu', padding=\"same\"))\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del feature_extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "x_train_rf = feature_extractor.predict(x_train)\n",
    "x_test_rf = feature_extractor.predict(x_test)\n",
    "\n",
    "RF_model.fit(x_train_rf, y_train)\n",
    "RF_pred = RF_model.predict(x_test_rf)\n",
    "\n",
    "cm = confusion_matrix(y_test, RF_pred)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "fig.suptitle('accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae5ed6e59739fd9c8a6a8aa249c06f0d19f950643afb8c47bef30ff59ac336a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
